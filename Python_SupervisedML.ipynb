{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMV1mgTdl6eG4mrfnQSxoSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuraishasb/chasingflights/blob/main/Python_SupervisedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 | Introduction\n",
        "\n",
        "In this report, we experiment the use of machine learning operators, mainly Supervised Learning, on 2 different data sets. We begin with the Classification analysis on the ----- data set, before moving on to the Regression analysis on the ----- data set."
      ],
      "metadata": {
        "id": "058y0wpsRXGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 | Regression Task\n"
      ],
      "metadata": {
        "id": "mVNhWBQYRioR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data visulisation\n",
        "import pandas as pd # analyze data\n",
        "import numpy as np # work with arrays\n",
        "import scipy.stats as stats # for statistical procedures such as t-test etc.\n",
        "import seaborn as sns # data visualisation library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#libraries used for handling missing and non-numeric values - part of data cleaning\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "#Pipeline : Chains all steps of the workflow for a more streamlined procedure.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "#Feature selection\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression,chi2\n",
        "\n",
        "#Training data\n",
        "from sklearn.model_selection import train_test_split #Split arrays or matrices into random train and test subsets.\n",
        "from sklearn.model_selection import cross_val_score # Evaluate a score by cross-validation.\n",
        "from sklearn.model_selection import StratifiedShuffleSplit #Random permutation cross-validator\n",
        "from sklearn.model_selection import GridSearchCV # Exhaustive search over specified parameter values for an estimator\n",
        "\n",
        "#linear regression\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "#Decision tree and SVM\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#R2 square and mean squared error\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "#KNN classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Gaussian Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "Dbnbih-rSP24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: EDA\n",
        "\n",
        "We use exploratory data analysis (EDA) to investigate data sets and summarize their main characteristics, which can be done by employing data visualization methods."
      ],
      "metadata": {
        "id": "SFCppZUvRpGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "df = pd.read_csv('/content/drive/My Drive/DAC/insurance.csv')"
      ],
      "metadata": {
        "id": "_xLfytgHSSEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fowORXDPNyj8"
      },
      "outputs": [],
      "source": [
        "# checking for duplicates + remove duplicates\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# check for null values\n",
        "df.isnull().sum()\n",
        "\n",
        "# remove all the outliers from the data. Outliers can either be Q1-(1.5*IQR) or Q3+(1.5*IQR)\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "outliers = (df < lower_bound) | (df > upper_bound)\n",
        "\n",
        "data = df[~outliers]\n",
        "data = data.dropna()\n",
        "sns.boxplot(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Prediction Diagnosis of Breast Cancer"
      ],
      "metadata": {
        "id": "ek5PDP16Sc6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign all the missing values of the numerical data with the medians and scale the data using StandardScaler\n",
        "\n",
        "# assign all the categorical data with numerical values using OrdinalEncoder\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "age = data['age'].values.reshape(-1,1)\n",
        "data['age'] = ordinal_encoder.fit_transform(age)\n",
        "\n",
        "\n",
        "sex = data['sex'].values.reshape(-1,1)\n",
        "data['sex'] = ordinal_encoder.fit_transform(sex)\n",
        "\n",
        "region = data['region'].values.reshape(-1,1)\n",
        "data['region'] = ordinal_encoder.fit_transform(region)\n",
        "\n",
        "smoker = data['smoker'].values.reshape(-1,1)\n",
        "data['smoker'] = ordinal_encoder.fit_transform(smoker)\n",
        "\n",
        "# feature selection - split the data into features and targets. We want the target/dependent variable to be 'charges'.\n",
        "target = data['charges']\n",
        "features = data.loc[:, data.columns != 'charges']\n",
        "\n",
        "selected_features = []\n",
        "selector = SelectKBest(f_regression, k = 'all')\n",
        "selector.fit_transform(features, target)\n",
        "\n",
        "supports = selector.get_support()\n",
        "\n",
        "print(supports)\n",
        "print(features.columns)\n",
        "\n",
        "for support, feature in zip(supports, features.columns):\n",
        "\n",
        "  if (support == True):\n",
        "    selected_features.append(feature)\n",
        "\n",
        "print('Selected features are: ', selected_features)\n",
        "\n",
        "# split the feature and target into train and test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.3, random_state = 13)"
      ],
      "metadata": {
        "id": "xL3mdMK0Sdv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1: Linear Regression\n",
        "\n",
        "Linear regression model is a basic and commonly used type of predictive analysis - it assumes a linear relationship between the independent variable and the dependent variable, and aims to find the best-fitting line that describes the relationship."
      ],
      "metadata": {
        "id": "hem631N_SirC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train them in these 3 regressions and find their respective root mean squared error and coefficient of determination (r^2)\n",
        "# simple linear regression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "predictions = model.predict(X_test)\n",
        "r2_lr = r2_score(Y_test, predictions)\n",
        "mse_lr = mean_squared_error(Y_test, predictions)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "\n",
        "print('R2 score of the regression model is: ', r2_lr)\n",
        "print('RMSE score of the regression model is: ', mse_lr)\n",
        "\n",
        "#does not take into account multicollinearity\n",
        "\n",
        "plt.scatter(Y_test, predictions, alpha = 0.7)"
      ],
      "metadata": {
        "id": "Q79AhzA1Si1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.3: Ridge Regression\n",
        "\n",
        "Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. We’ll use the `glmnet()` function to fit the ridge regression model and specify `alpha=0`."
      ],
      "metadata": {
        "id": "Sa4cy5-USi9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ridge regression\n",
        "model = Ridge(alpha = 0.5)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "r2_rr = r2_score(Y_test, predictions)\n",
        "mse_rr = mean_squared_error(Y_test, predictions)\n",
        "rmse_rr = np.sqrt(mse_rr)\n",
        "\n",
        "print('R2 score of the regression model is: ', r2_rr)\n",
        "print('RMSE score of the regression model is: ', rmse_rr)"
      ],
      "metadata": {
        "id": "61HM8pPUSjEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.2.4: Lasso Regression\n",
        "\n",
        "Lasso regression is another model tuning method, similar to ridge, that is used to analyse data with multicollinearity present. We’ll use the `glmnet()` function as well to fit the lasso regression model but specify `alpha=1` instead."
      ],
      "metadata": {
        "id": "W6K2QyOfSjLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lasso regression\n",
        "model = Lasso(alpha = 0.5)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "r2_lr = r2_score(Y_test, predictions)\n",
        "mse_lr = mean_squared_error(Y_test, predictions)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "\n",
        "print('R2 score of the regression model is: ', r2_lr)\n",
        "print('RMSE score of the regression model is: ', rmse_lr)"
      ],
      "metadata": {
        "id": "CimX7rhTSjRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Final Analyisis"
      ],
      "metadata": {
        "id": "CDDbYWHwSjYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a report\n",
        "models = pd.DataFrame({\n",
        "    'Model': ['Simple Linear Regression', 'Ridge Regression', 'Lasso Regression'],\n",
        "    'R2 Score': [r2_lr, r2_rr, r2_lr],\n",
        "    'RMSE Score': [rmse_lr, rmse_rr, rmse_lr]})\n",
        "models"
      ],
      "metadata": {
        "id": "JliYGZUrSjen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 | Classification Task\n"
      ],
      "metadata": {
        "id": "8kOQkMUU0PIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This time let “smokers” be the target, the rest as the features\n",
        "\n",
        "target = data['smoker']\n",
        "features = data.loc[:, data.columns != 'smoker']\n",
        "\n",
        "selected_features = []\n",
        "selector = SelectKBest(f_regression, k = 'all')\n",
        "selector.fit_transform(features, target)\n",
        "\n",
        "supports = selector.get_support()\n",
        "\n",
        "print(supports)\n",
        "print(features.columns)\n",
        "\n",
        "for support, feature in zip(supports, features.columns):\n",
        "\n",
        "  if (support == True):\n",
        "    selected_features.append(feature)\n",
        "\n",
        "print('Selected features are: ', selected_features)"
      ],
      "metadata": {
        "id": "9dHO2Ovl0b_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.3, random_state = 31)"
      ],
      "metadata": {
        "id": "tYRBZd-r0dH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify the “smokers” using: (1) K Nearest Neighbour\n",
        "\n",
        "KNN = KNeighborsClassifier(n_neighbors = 5)\n",
        "KNN.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = KNN.predict(X_test)\n",
        "\n",
        "accuracy_KNN = round(metrics.accuracy_score(Y_test, Y_pred)*100, 2)\n",
        "print('Accuracy of KNN is ', accuracy_KNN)"
      ],
      "metadata": {
        "id": "IzcX4pbS0fmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) Logistic Regression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = LR.predict(X_test)\n",
        "\n",
        "accuracy_LR = round(metrics.accuracy_score(Y_test, Y_pred)*100, 2)\n",
        "print('Accuracy of LR is ', accuracy_LR)"
      ],
      "metadata": {
        "id": "0dL8D5rN0kzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) Decision Tree Classifier\n",
        "\n",
        "DTC = DecisionTreeClassifier()\n",
        "\n",
        "DTC.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = DTC.predict(X_test)\n",
        "\n",
        "accuracy_DTC = round(metrics.accuracy_score(Y_test, Y_pred)*100, 2)\n",
        "print('Accuracy of DTC is ', accuracy_DTC)"
      ],
      "metadata": {
        "id": "o19H5Kdx0lQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Support Vector Machine\n",
        "\n",
        "SVC = SVC()\n",
        "\n",
        "SVC.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = SVC.predict(X_test)\n",
        "\n",
        "accuracy_SVC = round(metrics.accuracy_score(Y_test, Y_pred)*100, 2)\n",
        "print('Accuracy of SVC is ', accuracy_SVC)"
      ],
      "metadata": {
        "id": "f1RzgRbf0nWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) Naive Bayes Classifier\n",
        "\n",
        "Gaussian = GaussianNB()\n",
        "\n",
        "Gaussian.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = Gaussian.predict(X_test)\n",
        "\n",
        "accuracy_Gaussian = round(metrics.accuracy_score(Y_test, Y_pred)*100, 2)\n",
        "print('Accuracy of Gaussian is ', accuracy_Gaussian)"
      ],
      "metadata": {
        "id": "qvmUdg_Y0pTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Produce a report for Step 5, sorting the accuracy values in descending order\n",
        "\n",
        "models = pd.DataFrame({\n",
        "    'Model':['KNN', 'Naive Bayes', 'Logistic Regression','Decision Tree Classifier', 'Support Vector Machines'],\n",
        "    'Score':[accuracy_KNN, accuracy_Gaussian, accuracy_LR, accuracy_DTC, accuracy_SVC]\n",
        "})\n",
        "\n",
        "models"
      ],
      "metadata": {
        "id": "TC_gsfjY0u_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}