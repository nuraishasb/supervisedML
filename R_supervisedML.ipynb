{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSFjTVd/c31V0wWZyTNxvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuraishasb/chasingflights/blob/main/R_supervisedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 | Introduction\n",
        "\n",
        "In this report, we experiment the use of machine learning operators, mainly Supervised Learning, on 2 different data sets. We begin with the Classification analysis on the Breast Cancer data set, before moving on to the Regression analysis on the Boston data set."
      ],
      "metadata": {
        "id": "2m8tZuXCGjnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 | Classification Task\n",
        "\n",
        "Classification is a type of supervised machine learning where algorithms learn from the data to predict an outcome or event in the future. In this part of the report, we will be using the Breast Cancer data set to predict the diagnosis of breast cancer. https://archive.ics.uci.edu/dataset/45/heart+disease for more details of the data set."
      ],
      "metadata": {
        "id": "0aT7IHLlGnap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: EDA\n",
        "\n",
        "We use exploratory data analysis (EDA) to investigate data sets and summarize their main characteristics, which can be done by employing data visualization methods.\n",
        "\n",
        "The `str()` function provides information of the structure of the variables. It can be seen that the data set is mostly made up of numerical variables, with the the exception of variables `id`, `diagnosis` and `X`."
      ],
      "metadata": {
        "id": "mZTiI0YRGp97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUUYjZ0sGcq7"
      },
      "outputs": [],
      "source": [
        "install.packages(\"googledrive\")\n",
        "library(googledrive)\n",
        "drive_auth(use_oob = TRUE)\n",
        "\n",
        "data <- read.csv('/content/breastcancer.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "BreastCancer <- read.csv('breastcancer.csv')\n",
        "\n",
        "#examining the structure of the data set\n",
        "str(BreastCancer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La4kBtPDGjHI",
        "outputId": "2d709f18-0705-46b1-8f8c-60cd63aa257e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t569 obs. of  33 variables:\n",
            " $ id                     : int  842302 842517 84300903 84348301 84358402 843786 844359 84458202 844981 84501001 ...\n",
            " $ diagnosis              : chr  \"M\" \"M\" \"M\" \"M\" ...\n",
            " $ radius_mean            : num  18 20.6 19.7 11.4 20.3 ...\n",
            " $ texture_mean           : num  10.4 17.8 21.2 20.4 14.3 ...\n",
            " $ perimeter_mean         : num  122.8 132.9 130 77.6 135.1 ...\n",
            " $ area_mean              : num  1001 1326 1203 386 1297 ...\n",
            " $ smoothness_mean        : num  0.1184 0.0847 0.1096 0.1425 0.1003 ...\n",
            " $ compactness_mean       : num  0.2776 0.0786 0.1599 0.2839 0.1328 ...\n",
            " $ concavity_mean         : num  0.3001 0.0869 0.1974 0.2414 0.198 ...\n",
            " $ concave.points_mean    : num  0.1471 0.0702 0.1279 0.1052 0.1043 ...\n",
            " $ symmetry_mean          : num  0.242 0.181 0.207 0.26 0.181 ...\n",
            " $ fractal_dimension_mean : num  0.0787 0.0567 0.06 0.0974 0.0588 ...\n",
            " $ radius_se              : num  1.095 0.543 0.746 0.496 0.757 ...\n",
            " $ texture_se             : num  0.905 0.734 0.787 1.156 0.781 ...\n",
            " $ perimeter_se           : num  8.59 3.4 4.58 3.44 5.44 ...\n",
            " $ area_se                : num  153.4 74.1 94 27.2 94.4 ...\n",
            " $ smoothness_se          : num  0.0064 0.00522 0.00615 0.00911 0.01149 ...\n",
            " $ compactness_se         : num  0.049 0.0131 0.0401 0.0746 0.0246 ...\n",
            " $ concavity_se           : num  0.0537 0.0186 0.0383 0.0566 0.0569 ...\n",
            " $ concave.points_se      : num  0.0159 0.0134 0.0206 0.0187 0.0188 ...\n",
            " $ symmetry_se            : num  0.03 0.0139 0.0225 0.0596 0.0176 ...\n",
            " $ fractal_dimension_se   : num  0.00619 0.00353 0.00457 0.00921 0.00511 ...\n",
            " $ radius_worst           : num  25.4 25 23.6 14.9 22.5 ...\n",
            " $ texture_worst          : num  17.3 23.4 25.5 26.5 16.7 ...\n",
            " $ perimeter_worst        : num  184.6 158.8 152.5 98.9 152.2 ...\n",
            " $ area_worst             : num  2019 1956 1709 568 1575 ...\n",
            " $ smoothness_worst       : num  0.162 0.124 0.144 0.21 0.137 ...\n",
            " $ compactness_worst      : num  0.666 0.187 0.424 0.866 0.205 ...\n",
            " $ concavity_worst        : num  0.712 0.242 0.45 0.687 0.4 ...\n",
            " $ concave.points_worst   : num  0.265 0.186 0.243 0.258 0.163 ...\n",
            " $ symmetry_worst         : num  0.46 0.275 0.361 0.664 0.236 ...\n",
            " $ fractal_dimension_worst: num  0.1189 0.089 0.0876 0.173 0.0768 ...\n",
            " $ X                      : logi  NA NA NA NA NA NA ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable `X` is redundant as it does not contain any valuable information hence we remove it. The `is.na()` function checks the NA field in a data frame. We take the sum of the function to find the total number of NA values in our data set, which is 0."
      ],
      "metadata": {
        "id": "RD2zQdK3HWTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing column `X`\n",
        "BC <- BreastCancer[,-33]\n",
        "\n",
        "#Finding if there are NA values\n",
        "sum(is.na(BC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ifNTgNrtHYBG",
        "outputId": "a349df7e-34b0-4114-b9dd-2c9bc925d32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0"
            ],
            "text/markdown": "0",
            "text/latex": "0",
            "text/plain": [
              "[1] 0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `diagnosis` variable is made up of solely 'M's and 'N's where M stands for malignant and B stands for benign. By tabulating the data, we can deduce that there are more number of observations of benign breast cancer tumors than malignant ones."
      ],
      "metadata": {
        "id": "Gpw2dsa-Hil8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tabulating the binary variable `target`\n",
        "table(BC$diagnosis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "eiiOrlcRHjfP",
        "outputId": "caf5841c-440a-4989-875e-55809b040369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "  B   M \n",
              "357 212 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned above, our aim in this section of the report is to predict the diagnosis of breast cancer, given the measurements of the tumor and breast mass. Thus, our independent variable is the `diagnosis` variable. We start off by converting the variable into binary, where Malignant takes the value 1, and 0 for Benign."
      ],
      "metadata": {
        "id": "zU-RvsZFHniW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert `diagnosis` to binary: benign and malignant\n",
        "diagnosis01 <-  rep(0, length(BC$diagnosis)) #create vector of 0s of length `diagnosis`\n",
        "diagnosis01[BC$diagnosis=='M'] <- 1 #condition where if `diagnosis` = M, turn it to 1\n",
        "BC <- data.frame(BC, diagnosis01) #adding to the data frame"
      ],
      "metadata": {
        "id": "NYRdiR1iHoZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we investigate the association between `diagnosis01` to the other features. We do so by using the `cor()` function, which measures the correlation coefficient value between two vectors."
      ],
      "metadata": {
        "id": "BtKlbxazIEbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cor <- cor(BC[,-1:-2]) #correlation of data set, excluding columns 1 and 2\n",
        "results <- as.table(cor[,31]) #table of correlations between `diagnosis1' with other variables\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "MOkm4DvUIMlK",
        "outputId": "beae3b64-812e-4389-cc99-6ec3fb4d4a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            radius_mean            texture_mean          perimeter_mean \n",
              "            0.730028511             0.415185300             0.742635530 \n",
              "              area_mean         smoothness_mean        compactness_mean \n",
              "            0.708983837             0.358559965             0.596533678 \n",
              "         concavity_mean     concave.points_mean           symmetry_mean \n",
              "            0.696359707             0.776613840             0.330498554 \n",
              " fractal_dimension_mean               radius_se              texture_se \n",
              "           -0.012837603             0.567133821            -0.008303333 \n",
              "           perimeter_se                 area_se           smoothness_se \n",
              "            0.556140703             0.548235940            -0.067016011 \n",
              "         compactness_se            concavity_se       concave.points_se \n",
              "            0.292999244             0.253729766             0.408042333 \n",
              "            symmetry_se    fractal_dimension_se            radius_worst \n",
              "           -0.006521756             0.077972417             0.776453779 \n",
              "          texture_worst         perimeter_worst              area_worst \n",
              "            0.456902821             0.782914137             0.733825035 \n",
              "       smoothness_worst       compactness_worst         concavity_worst \n",
              "            0.421464861             0.590998238             0.659610210 \n",
              "   concave.points_worst          symmetry_worst fractal_dimension_worst \n",
              "            0.793566017             0.416294311             0.323872189 \n",
              "            diagnosis01 \n",
              "            1.000000000 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible values of the correlation coefficient range from -1 to +1, with -1 indicating a perfectly linear negative, and +1 indicating a perfectly linear positive correlation. A correlation coefficient close to 0 suggests little, if any, correlation. The other features seem most likely to be useful in predicting `diagnosis01` are: radius_mean, perimeter_mean, area_mean, concave.points_mean, radius_worst, perimeter_worst, area_worst, and concave.points_worst."
      ],
      "metadata": {
        "id": "J-CRnUu1IagD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Prediction Diagnosis of Breast Cancer\n",
        "\n",
        "We begin the analysis by splitting the data, using the 70/30 ratio."
      ],
      "metadata": {
        "id": "zH7rmf3vIclp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to make sure we get the same results for randomization\n",
        "set.seed(13)\n",
        "\n",
        "#taking 70% of the data for training\n",
        "train.size <-  nrow(BC) * 0.7\n",
        "\n",
        "#taking a sample of the total rows by the number of train.size\n",
        "train <-  sample(1:nrow(BC), train.size) #sample of the rows of the training set\n",
        "test <-  -train #the other 30% for test - this is done by indexing.\n",
        "\n",
        "#subsetting the data set by the train and test rows respectively\n",
        "BC.train <-  BC[train, ]\n",
        "BC.test <-  BC[test, ]\n",
        "diagnosis01.test <-  diagnosis01[test]"
      ],
      "metadata": {
        "id": "5Pu4UfgDJhSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1: Linear Discriminant Analysis\n",
        "\n",
        "The linear discriminant analysis (LDA) finds a linear combination of features that best separates the classes in a data set. We will be using the `lda()` function from the `MASS` package to fit the LDA model to our data."
      ],
      "metadata": {
        "id": "shJRxwKzLWfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the package\n",
        "library(MASS)\n",
        "\n",
        "#learn the model on train set\n",
        "lda.fit <-  lda(diagnosis01 ~ radius_mean + perimeter_mean + area_mean + concave.points_mean + radius_worst\n",
        "                + perimeter_worst + area_worst + concave.points_worst,\n",
        "                data = BC.train)\n",
        "lda.fit #view model output\n",
        "\n",
        "#predicting on test set\n",
        "lda.pred <- predict(lda.fit, BC.test)\n",
        "names(lda.pred)\n",
        "head(lda.pred$class) #view predicted class for first six observations in test set\n",
        "head(lda.pred$posterior) #view posterior probabilities for first six observations in test set\n",
        "head(lda.pred$x) #view linear discriminants for first six observations in test set\n",
        "\n",
        "\n",
        "#finding misclassification error rate (MER), which gives the proportion of incorrect predictions\n",
        "mean(lda.pred$class != diagnosis01.test)\n",
        "LDAMER <- mean(lda.pred$class != diagnosis01.test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7MQB_i0JLj--",
        "outputId": "f34cf772-c586-4dc1-aa60-19e92d5753b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Call:\n",
              "lda(diagnosis01 ~ radius_mean + perimeter_mean + area_mean + \n",
              "    concave.points_mean + radius_worst + perimeter_worst + area_worst + \n",
              "    concave.points_worst, data = BC.train)\n",
              "\n",
              "Prior probabilities of groups:\n",
              "        0         1 \n",
              "0.6482412 0.3517588 \n",
              "\n",
              "Group means:\n",
              "  radius_mean perimeter_mean area_mean concave.points_mean radius_worst\n",
              "0    12.17950       78.34996  464.2903          0.02667181     13.42559\n",
              "1    17.55879      116.16007  986.3771          0.09022679     21.26043\n",
              "  perimeter_worst area_worst concave.points_worst\n",
              "0        87.44453   561.3868            0.0768624\n",
              "1       142.60050  1437.0136            0.1858921\n",
              "\n",
              "Coefficients of linear discriminants:\n",
              "                              LD1\n",
              "radius_mean          -0.841894415\n",
              "perimeter_mean       -0.125061066\n",
              "area_mean             0.012546995\n",
              "concave.points_mean  17.311321903\n",
              "radius_worst          1.615371361\n",
              "perimeter_worst      -0.002705764\n",
              "area_worst           -0.009538506\n",
              "concave.points_worst  9.631020355"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'class'</li><li>'posterior'</li><li>'x'</li></ol>\n"
            ],
            "text/markdown": "1. 'class'\n2. 'posterior'\n3. 'x'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'class'\n\\item 'posterior'\n\\item 'x'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] \"class\"     \"posterior\" \"x\"        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>0</li></ol>\n",
              "\n",
              "<details>\n",
              "\t<summary style=display:list-item;cursor:pointer>\n",
              "\t\t<strong>Levels</strong>:\n",
              "\t</summary>\n",
              "\t<style>\n",
              "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
              "\t.list-inline>li {display: inline-block}\n",
              "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "\t</style>\n",
              "\t<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
              "</details>"
            ],
            "text/markdown": "1. 1\n2. 1\n3. 1\n4. 1\n5. 1\n6. 0\n\n\n\n**Levels**: 1. '0'\n2. '1'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 1\n\\item 1\n\\item 1\n\\item 1\n\\item 1\n\\item 0\n\\end{enumerate*}\n\n\\emph{Levels}: \\begin{enumerate*}\n\\item '0'\n\\item '1'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 1 1 1 1 1 0\n",
              "Levels: 0 1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 6 × 2 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>3</th><td>1.265956e-05</td><td>0.9999873</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1.029342e-05</td><td>0.9999897</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>6.140966e-04</td><td>0.9993859</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>9.524947e-02</td><td>0.9047505</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>4.141766e-02</td><td>0.9585823</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>6.150928e-01</td><td>0.3849072</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 6 × 2 of type dbl\n\n| <!--/--> | 0 | 1 |\n|---|---|---|\n| 3 | 1.265956e-05 | 0.9999873 |\n| 4 | 1.029342e-05 | 0.9999897 |\n| 7 | 6.140966e-04 | 0.9993859 |\n| 8 | 9.524947e-02 | 0.9047505 |\n| 10 | 4.141766e-02 | 0.9585823 |\n| 11 | 6.150928e-01 | 0.3849072 |\n\n",
            "text/latex": "A matrix: 6 × 2 of type dbl\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n\\hline\n\t3 & 1.265956e-05 & 0.9999873\\\\\n\t4 & 1.029342e-05 & 0.9999897\\\\\n\t7 & 6.140966e-04 & 0.9993859\\\\\n\t8 & 9.524947e-02 & 0.9047505\\\\\n\t10 & 4.141766e-02 & 0.9585823\\\\\n\t11 & 6.150928e-01 & 0.3849072\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   0            1        \n",
              "3  1.265956e-05 0.9999873\n",
              "4  1.029342e-05 0.9999897\n",
              "7  6.140966e-04 0.9993859\n",
              "8  9.524947e-02 0.9047505\n",
              "10 4.141766e-02 0.9585823\n",
              "11 6.150928e-01 0.3849072"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 6 × 1 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>LD1</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>3</th><td>3.8373071</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>3.8948092</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>2.7583708</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>1.3289242</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>1.5764263</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>0.5730318</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 6 × 1 of type dbl\n\n| <!--/--> | LD1 |\n|---|---|\n| 3 | 3.8373071 |\n| 4 | 3.8948092 |\n| 7 | 2.7583708 |\n| 8 | 1.3289242 |\n| 10 | 1.5764263 |\n| 11 | 0.5730318 |\n\n",
            "text/latex": "A matrix: 6 × 1 of type dbl\n\\begin{tabular}{r|l}\n  & LD1\\\\\n\\hline\n\t3 & 3.8373071\\\\\n\t4 & 3.8948092\\\\\n\t7 & 2.7583708\\\\\n\t8 & 1.3289242\\\\\n\t10 & 1.5764263\\\\\n\t11 & 0.5730318\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   LD1      \n",
              "3  3.8373071\n",
              "4  3.8948092\n",
              "7  2.7583708\n",
              "8  1.3289242\n",
              "10 1.5764263\n",
              "11 0.5730318"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.087719298245614"
            ],
            "text/markdown": "0.087719298245614",
            "text/latex": "0.087719298245614",
            "text/plain": [
              "[1] 0.0877193"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LDA has a 8.77% test error rate.**\n",
        "\n",
        "#### 2.2.2: Quadratic Discriminant Analysis\n",
        "\n",
        "The quadratic discriminant analysis (QDA) finds a non-linear combination of features that best separates the classes in a data set. Similarly, we will be using the `qda()` function from the `MASS` package to fit the QDA model to our data."
      ],
      "metadata": {
        "id": "3cbSBFC_N9Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learn the model\n",
        "qda.fit <-  qda(diagnosis01 ~ radius_mean + perimeter_mean + area_mean + concave.points_mean + radius_worst\n",
        "                + perimeter_worst + area_worst + concave.points_worst,\n",
        "                data = BC.train)\n",
        "\n",
        "# form the prediction on test set\n",
        "qda.pred <-  predict(qda.fit, BC.test)\n",
        "names(qda.pred)\n",
        "head(qda.pred$class) #view predicted class for first six observations in test set\n",
        "head(qda.pred$posterior) #view posterior probabilities for first six observations in test set\n",
        "\n",
        "\n",
        "#compute estimate of test error.\n",
        "#mean where prediction does not match the real value\n",
        "mean(qda.pred$class != diagnosis01.test)\n",
        "QDAMER <- mean(qda.pred$class != diagnosis01.test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "uEoQl7i7N-Kl",
        "outputId": "f3dd8a22-bbf4-4172-fdb5-0831e6492fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'class'</li><li>'posterior'</li></ol>\n"
            ],
            "text/markdown": "1. 'class'\n2. 'posterior'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'class'\n\\item 'posterior'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] \"class\"     \"posterior\""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li></ol>\n",
              "\n",
              "<details>\n",
              "\t<summary style=display:list-item;cursor:pointer>\n",
              "\t\t<strong>Levels</strong>:\n",
              "\t</summary>\n",
              "\t<style>\n",
              "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
              "\t.list-inline>li {display: inline-block}\n",
              "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "\t</style>\n",
              "\t<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
              "</details>"
            ],
            "text/markdown": "1. 1\n2. 1\n3. 1\n4. 1\n5. 1\n6. 1\n\n\n\n**Levels**: 1. '0'\n2. '1'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 1\n\\item 1\n\\item 1\n\\item 1\n\\item 1\n\\item 1\n\\end{enumerate*}\n\n\\emph{Levels}: \\begin{enumerate*}\n\\item '0'\n\\item '1'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 1 1 1 1 1 1\n",
              "Levels: 0 1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 6 × 2 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>3</th><td>8.260391e-118</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 3.172709e-20</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>7</th><td> 4.348630e-97</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>8</th><td> 7.383542e-13</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>10</th><td> 1.070304e-10</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>11</th><td> 1.013080e-19</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 6 × 2 of type dbl\n\n| <!--/--> | 0 | 1 |\n|---|---|---|\n| 3 | 8.260391e-118 | 1 |\n| 4 |  3.172709e-20 | 1 |\n| 7 |  4.348630e-97 | 1 |\n| 8 |  7.383542e-13 | 1 |\n| 10 |  1.070304e-10 | 1 |\n| 11 |  1.013080e-19 | 1 |\n\n",
            "text/latex": "A matrix: 6 × 2 of type dbl\n\\begin{tabular}{r|ll}\n  & 0 & 1\\\\\n\\hline\n\t3 & 8.260391e-118 & 1\\\\\n\t4 &  3.172709e-20 & 1\\\\\n\t7 &  4.348630e-97 & 1\\\\\n\t8 &  7.383542e-13 & 1\\\\\n\t10 &  1.070304e-10 & 1\\\\\n\t11 &  1.013080e-19 & 1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "   0             1\n",
              "3  8.260391e-118 1\n",
              "4   3.172709e-20 1\n",
              "7   4.348630e-97 1\n",
              "8   7.383542e-13 1\n",
              "10  1.070304e-10 1\n",
              "11  1.013080e-19 1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.0584795321637427"
            ],
            "text/markdown": "0.0584795321637427",
            "text/latex": "0.0584795321637427",
            "text/plain": [
              "[1] 0.05847953"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QDA has a 5.85% test error rate.**\n",
        "\n",
        "#### 2.2.3: Logistic Regression\n",
        "\n",
        "Logistic regression predicts the categorical dependent variable using a given set of independent variables. We will be using the `glm()` function and specify `family=”binomial”` so that R fits a logistic regression model to the data set. GLM stands for general linear model."
      ],
      "metadata": {
        "id": "N0AqyaNFOBLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learn model: trained on training data\n",
        "glm.fit <-  glm(diagnosis01 ~ radius_mean + perimeter_mean + area_mean + concave.points_mean + radius_worst\n",
        "                + perimeter_worst + area_worst + concave.points_worst,\n",
        "              data = BC.train,\n",
        "              family = binomial)\n",
        "summary(glm.fit) #view model summary\n",
        "\n",
        "#obtain predictions on test set\n",
        "glm.probs <-  predict(glm.fit, BC.test, type = \"response\") #probability that each observation is malignant\n",
        "#using a threshold to decide on final diagnosis\n",
        "glm.pred <-  rep(0, length(glm.probs))\n",
        "glm.pred[glm.probs > 0.7] <- 1 #threshold chosen is 0.7\n",
        "\n",
        "#creating ROC curve\n",
        "install.packages(\"verification\")\n",
        "library(verification)\n",
        "roc.plot(diagnosis01.test, glm.probs, xlab = \"False Positive Rate\",\n",
        "ylab = \"True Positive Rate\")\n",
        "\n",
        "#evaluate prediction quality\n",
        "mean(glm.pred != diagnosis01.test)\n",
        "LogRegMER <- mean(glm.pred != diagnosis01.test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Eb2hTY0YODvn",
        "outputId": "1c329b08-df92-4ff0-b8d3-cdf919c90022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message:\n",
            "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "glm(formula = diagnosis01 ~ radius_mean + perimeter_mean + area_mean + \n",
              "    concave.points_mean + radius_worst + perimeter_worst + area_worst + \n",
              "    concave.points_worst, family = binomial, data = BC.train)\n",
              "\n",
              "Coefficients:\n",
              "                     Estimate Std. Error z value Pr(>|z|)  \n",
              "(Intercept)          -0.06650   13.19228  -0.005   0.9960  \n",
              "radius_mean           2.22045    5.80321   0.383   0.7020  \n",
              "perimeter_mean       -0.20649    0.63727  -0.324   0.7459  \n",
              "area_mean            -0.04627    0.03904  -1.185   0.2359  \n",
              "concave.points_mean  77.19324   47.28673   1.632   0.1026  \n",
              "radius_worst         -2.76489    2.49443  -1.108   0.2677  \n",
              "perimeter_worst      -0.03212    0.16584  -0.194   0.8464  \n",
              "area_worst            0.07016    0.02840   2.470   0.0135 *\n",
              "concave.points_worst 34.17197   19.31499   1.769   0.0769 .\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "(Dispersion parameter for binomial family taken to be 1)\n",
              "\n",
              "    Null deviance: 516.229  on 397  degrees of freedom\n",
              "Residual deviance:  56.568  on 389  degrees of freedom\n",
              "AIC: 74.568\n",
              "\n",
              "Number of Fisher Scoring iterations: 10\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘dotCall64’, ‘spam’, ‘maps’, ‘proxy’, ‘fields’, ‘CircStats’, ‘dtw’\n",
            "\n",
            "\n",
            "Loading required package: fields\n",
            "\n",
            "Loading required package: spam\n",
            "\n",
            "Spam version 2.10-0 (2023-10-23) is loaded.\n",
            "Type 'help( Spam)' or 'demo( spam)' for a short introduction \n",
            "and overview of this package.\n",
            "Help for individual functions is also obtained by adding the\n",
            "suffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n",
            "\n",
            "\n",
            "Attaching package: ‘spam’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    backsolve, forwardsolve\n",
            "\n",
            "\n",
            "Loading required package: viridisLite\n",
            "\n",
            "\n",
            "Try help(fields) to get started.\n",
            "\n",
            "Loading required package: boot\n",
            "\n",
            "Loading required package: CircStats\n",
            "\n",
            "Loading required package: dtw\n",
            "\n",
            "Loading required package: proxy\n",
            "\n",
            "\n",
            "Attaching package: ‘proxy’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:spam’:\n",
            "\n",
            "    as.matrix\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    as.dist, dist\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:base’:\n",
            "\n",
            "    as.matrix\n",
            "\n",
            "\n",
            "Loaded dtw v1.23-1. See ?dtw for help, citation(\"dtw\") for use in publication.\n",
            "\n",
            "\n",
            "Registered S3 method overwritten by 'verification':\n",
            "  method    from\n",
            "  lines.roc pROC\n",
            "\n",
            "\n",
            "Attaching package: ‘verification’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:pROC’:\n",
            "\n",
            "    lines.roc\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.064327485380117"
            ],
            "text/markdown": "0.064327485380117",
            "text/latex": "0.064327485380117",
            "text/plain": [
              "[1] 0.06432749"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Plot with title “ROC Curve”"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nRU5ErkJggg=="
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression has a 6.43% test error rate.**\n",
        "\n",
        "#### 2.2.4: K-Nearest Neighbour\n",
        "\n",
        "The K-Nearest Neighbor (KNN) algorithm stores all the available data and classifies a new data point based on the similarity. We will be using the `knn()` function from the `class` package to fit the KNN model to our data.\n"
      ],
      "metadata": {
        "id": "d6XnPngFOGYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(class)\n",
        "\n",
        "#binding the feature values by column for the train and test set respectively.\n",
        "train.X <- cbind(BC$radius_mean, BC$perimeter_mean, BC$area_mean, BC$concave.points_mean, BC$radius_worst, BC$perimeter_worst, BC$area_worst, BC$concave.points_worst)[train,]\n",
        "\n",
        "test.X <- cbind(BC$radius_mean, BC$perimeter_mean, BC$area_mean, BC$concave.points_mean, BC$radius_worst, BC$perimeter_worst, BC$area_worst, BC$concave.points_worst)[test,]\n",
        "\n",
        "train.diagnosis01 <-  diagnosis01[train]\n",
        "\n",
        "set.seed(13)\n",
        "# KNN (k=2)\n",
        "knn.pred2 <-  knn(train.X, test.X, train.diagnosis01, k = 2)\n",
        "mean(knn.pred2 != diagnosis01.test)\n",
        "KNN2MER <- mean(knn.pred2 != diagnosis01.test)\n",
        "\n",
        "# KNN (k=20)\n",
        "knn.pred20 <-  knn(train.X, test.X, train.diagnosis01, k = 20)\n",
        "mean(knn.pred20 != diagnosis01.test)\n",
        "KNN20MER <- mean(knn.pred20 != diagnosis01.test)\n",
        "\n",
        "# KNN (k=200)\n",
        "knn.pred200 <-  knn(train.X, test.X, train.diagnosis01, k = 200)\n",
        "mean(knn.pred200 != diagnosis01.test)\n",
        "KNN200MER <- mean(knn.pred200 != diagnosis01.test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "zHOXbyEfOI5j",
        "outputId": "f0382cbc-9ed1-4399-a9c8-5310d68e0ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.111111111111111"
            ],
            "text/markdown": "0.111111111111111",
            "text/latex": "0.111111111111111",
            "text/plain": [
              "[1] 0.1111111"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.087719298245614"
            ],
            "text/markdown": "0.087719298245614",
            "text/latex": "0.087719298245614",
            "text/plain": [
              "[1] 0.0877193"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.181286549707602"
            ],
            "text/markdown": "0.181286549707602",
            "text/latex": "0.181286549707602",
            "text/plain": [
              "[1] 0.1812865"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**k=2 has a 11.1% test error rate. k=20 has 8.77% test error rate. k=200 has a 18.1% test error rate. K of 20 seems to perform the best.**\n",
        "\n",
        "### 2.3: Final Analyisis"
      ],
      "metadata": {
        "id": "u2eQxs5rONUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a table of overall results\n",
        "mervalues <- matrix(c(LDAMER, QDAMER, LogRegMER, KNN2MER, KNN20MER, KNN200MER), ncol=1)\n",
        "colnames(mervalues) <- c('MER values')\n",
        "rownames(mervalues) <- c('LDA','QDA','Log Reg', 'KNN (K=2)', 'KNN (K=20)', 'KNN (K=200)')\n",
        "as.table(mervalues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "hxD83_NVOOHq",
        "outputId": "8775bc2a-0db2-424a-9aca-55bf7ac1aaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            MER values\n",
              "LDA         0.08771930\n",
              "QDA         0.05847953\n",
              "Log Reg     0.06432749\n",
              "KNN (K=2)   0.11111111\n",
              "KNN (K=20)  0.08771930\n",
              "KNN (K=200) 0.18128655"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QDA achieved the lowest test error rate.**"
      ],
      "metadata": {
        "id": "dClcamiEORZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 | Supervised Learning: Regression\n",
        "\n",
        "Regression is a type of supervised machine learning where algorithms learn from the data to predict a continuous value. In this part of the report, we will be using the Boston data set from the MASS package to predict the median value of owner-occupied homes in suburbs of Boston."
      ],
      "metadata": {
        "id": "pOQowxPpOTTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1: EDA\n",
        "\n",
        "Once again, we start off with some exploratory data analysis."
      ],
      "metadata": {
        "id": "ZGVLK1OzKdO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data\n",
        "library(MASS)\n",
        "\n",
        "#observing the structure\n",
        "str(Boston)\n",
        "\n",
        "#checking for NA value\n",
        "sum(is.na(Boston))\n",
        "\n",
        "#summary of `medv` variable\n",
        "summary(Boston$medv)\n",
        "\n",
        "#observing correlation\n",
        "pairs(Boston)"
      ],
      "metadata": {
        "id": "NDBe-tZ6KfXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2: Predicting the Median Housing Value in Boston\n",
        "\n",
        "We start off by splitting the data into training and testing sets using the same 70/30 ratio."
      ],
      "metadata": {
        "id": "KYrLdtFGKwln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "train.size2 <-  nrow(Boston) * 0.7 #taking 70% of the data for training\n",
        "\n",
        "#taking a sample of the total rows by the number of train.size\n",
        "train2 <-  sample(1:nrow(Boston), train.size2) #sample of the rows of the training set\n",
        "test2 <-  -train2 #the other 30% for test - this is done by indexing.\n",
        "\n",
        "#subset the Boston data set by the train and test rows respectively\n",
        "Boston.train <-  Boston[train2, ]\n",
        "Boston.test <-  Boston[test2, ]"
      ],
      "metadata": {
        "id": "6qXMBxfhKwu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1: Linear Regression\n",
        "\n",
        "Linear regression model is a basic and commonly used type of predictive analysis - it assumes a linear relationship between the independent variable and the dependent variable, and aims to find the best-fitting line that describes the relationship."
      ],
      "metadata": {
        "id": "VVpmvdHgK6Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting a linear model using least squares on training data\n",
        "lm.fit <-  lm(medv ~ . , data = Boston.train)\n",
        "#view model summary\n",
        "summary(lm.fit)\n",
        "\n",
        "#predicting on test data\n",
        "lm.pred <-  predict(lm.fit, Boston.test)\n",
        "\n",
        "#evaluate prediction quality using MSE\n",
        "mean((Boston.test[, \"medv\"] - lm.pred)^2)\n",
        "MSELM <- mean((Boston.test[, \"medv\"] - lm.pred)^2)"
      ],
      "metadata": {
        "id": "7u1gzGZxL5Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Least Squares has a MSE of 27.79.**\n",
        "\n",
        "try another one with squared variables or something"
      ],
      "metadata": {
        "id": "SkPP5nBHL9ug"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eUjcAKuMD9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2: Best Subset\n",
        "\n",
        "The best subset algorithm helps us pick the best model out of the many models we can potentially build with 13 features and one target. The `regsubsets()` function is for model selection, done by exhaustive search. It fits the input to every output/group of outputs, compare the models and find the one with the least error/BIC."
      ],
      "metadata": {
        "id": "YkYmqTiYMEOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(leaps)\n",
        "\n",
        "#model selection\n",
        "regfit.full <- regsubsets(medv ~ . , data = Boston.train, nvmax=15)\n",
        "\n",
        "reg.summary <- summary(regfit.full)\n",
        "best.model <- which.min(reg.summary$bic) #number of variables with the smallest BIC value\n",
        "#plotting the BIC curve across the number of variables\n",
        "plot(reg.summary$bic,xlab=\"Number of Variables\",ylab=\"BIC\",type='l')\n",
        "points(best.model,reg.summary$bic[best.model], col=\"red\",cex=2,pch=20)\n",
        "\n",
        "#predictions on test set\n",
        "Xtest <- model.matrix(medv ~ . , data = Boston.test) # get matrix X for test data\n",
        "#taking the estimated parameters from the model with lowest BIC\n",
        "coefbest <- coef(regfit.full,best.model)\n",
        "coefbest\n",
        "#'%*%' means matrix multiplication\n",
        "pred <- Xtest[,names(coefbest)]%*%coefbest # Xbeta\n",
        "\n",
        "#3. MSE\n",
        "mean((Boston.test$medv-pred)^2)\n",
        "MSEBS <- mean((Boston.test$medv-pred)^2)"
      ],
      "metadata": {
        "id": "O6qId7kOMKdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Subsets has a MSE of 31.01.**\n",
        "\n",
        "#### 3.2.3: Ridge Regression\n",
        "\n",
        "Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. We’ll use the `glmnet()` function to fit the ridge regression model and specify `alpha=0`."
      ],
      "metadata": {
        "id": "vVjbDGNPMRAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "library(glmnet)\n",
        "train.mat <-  model.matrix(medv ~ . , data = Boston.train)\n",
        "test.mat <-  model.matrix(medv ~ . , data = Boston.test)\n",
        "\n",
        "#cross validation code to find lambda value\n",
        "grid <-  10 ^ seq(4, -2, length = 100)\n",
        "mod.ridge <-  cv.glmnet(train.mat, Boston.train[, \"medv\"],\n",
        "                        alpha = 0, lambda = grid, thresh = 1e-12)\n",
        "lambda.best <-  mod.ridge$lambda.min\n",
        "lambda.best\n",
        "\n",
        "#prediction\n",
        "ridge.pred <-  predict(mod.ridge, newx = test.mat, s = lambda.best)\n",
        "mean((Boston.test[, \"medv\"] - ridge.pred)^2)\n",
        "MSERidge <- mean((Boston.test[, \"medv\"] - ridge.pred)^2)"
      ],
      "metadata": {
        "id": "2WhJuk1NMds3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression has a MSE of 27.86.**\n",
        "\n",
        "####3.2.4: Lasso Regression\n",
        "\n",
        "Lasso regression is another model tuning method, similar to ridge, that is used to analyse data with multicollinearity present. We’ll use the `glmnet()` function as well to fit the lasso regression model but specify `alpha=1` instead."
      ],
      "metadata": {
        "id": "JXm5PwBkMd1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cross validation code to find lambda value\n",
        "mod.lasso <-  cv.glmnet(train.mat, Boston.train[, \"medv\"],\n",
        "                        alpha = 1, lambda = grid, thresh = 1e-12)\n",
        "lambda.best <-  mod.lasso$lambda.min\n",
        "lambda.best\n",
        "\n",
        "#prediction\n",
        "lasso.pred <-  predict(mod.lasso, newx = test.mat, s = lambda.best)\n",
        "mean((Boston.test[, \"medv\"] - lasso.pred)^2)\n",
        "MSELasso <- mean((Boston.test[, \"medv\"] - lasso.pred)^2)\n",
        "\n",
        "#obtain the coefficient estimates\n",
        "mod.lasso <-  glmnet(model.matrix(medv ~ . , data = Boston),\n",
        "                     Boston[, \"medv\"], alpha = 1)\n",
        "predict(mod.lasso, s = lambda.best, type = \"coefficients\")"
      ],
      "metadata": {
        "id": "o0CDyCT8Mn1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression has a MSE of 27.81.**\n",
        "\n",
        "### 3.3: Final Analysis"
      ],
      "metadata": {
        "id": "0D-6AxLvMoAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a table of overall results\n",
        "msevalues <- matrix(c(MSELM, MSEBS, MSERidge, MSELasso), ncol=1)\n",
        "colnames(msevalues) <- c('MSE values')\n",
        "rownames(msevalues) <- c('Least Squares','Best Subset','Ridge', 'Lasso')\n",
        "as.table(msevalues)"
      ],
      "metadata": {
        "id": "NhOG4XdrMyBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Least Squares is the best performing model with the smallest MSE value.**"
      ],
      "metadata": {
        "id": "fGn3_eAbM1HE"
      }
    }
  ]
}